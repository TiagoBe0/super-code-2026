# Unified MD Analysis

Software unificado para anÃ¡lisis de estructuras cristalinas FCC/BCC en simulaciones de dinÃ¡mica molecular LAMMPS.

## ğŸ“‹ CaracterÃ­sticas

- **Alpha Shape**: DetecciÃ³n de superficie con Ghost Particles
- **Clustering**: SeparaciÃ³n de nanoporos con HDBSCAN, KMeans, MeanShift, Agglomerative
- **Preprocesamiento**: ExtracciÃ³n de 37 features geomÃ©tricas para Machine Learning
- **Training**: Entrenamiento de Random Forest para predicciÃ³n de vacancias
- **PredicciÃ³n**: Inferencia de vacancias en nuevos dumps

## ğŸ—ï¸ Estructura del Proyecto

```
unified_md_analysis/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ surface_detection.py  # Alpha Shape + Ghost Particles
â”‚   â”œâ”€â”€ clustering.py          # Clustering (HDBSCAN, KMeans, etc.)
â”‚   â”œâ”€â”€ preprocessing.py       # ExtracciÃ³n de 37 features
â”‚   â”œâ”€â”€ training.py            # Entrenamiento Random Forest
â”‚   â””â”€â”€ prediction.py          # PredicciÃ³n de vacancias
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ constants.py           # Constantes globales
â”‚   â””â”€â”€ lammps_parser.py       # Parser LAMMPS unificado
â”œâ”€â”€ cli/
â”‚   â”œâ”€â”€ alpha_shape.py         # CLI detecciÃ³n de superficie
â”‚   â”œâ”€â”€ cluster.py             # CLI clustering
â”‚   â”œâ”€â”€ preprocess.py          # CLI extracciÃ³n de features
â”‚   â”œâ”€â”€ train.py               # CLI training
â”‚   â””â”€â”€ predict.py             # CLI predicciÃ³n
â”œâ”€â”€ main.py                    # Orquestador principal
â””â”€â”€ requirements.txt
```

## ğŸš€ InstalaciÃ³n

```bash
# Clonar o copiar el directorio
cd unified_md_analysis

# Instalar dependencias
pip install -r requirements.txt

# Opcional: HDBSCAN (clustering avanzado)
pip install hdbscan
```

## ğŸ“– Uso

### 1ï¸âƒ£ Alpha Shape (DetecciÃ³n de Superficie)

Detecta Ã¡tomos superficiales eliminando bulk:

```bash
python main.py alpha_shape input.dump output_surface.dump

# Con parÃ¡metros personalizados
python main.py alpha_shape input.dump output.dump \
    --probe-radius 2.2 \
    --num-ghost-layers 3 \
    --smoothing 10
```

**ParÃ¡metros:**
- `--probe-radius`: Radio de sonda en Ã… (default: 2.0)
- `--lattice-param`: ParÃ¡metro de red (default: auto-detectar)
- `--num-ghost-layers`: Capas fantasma para PBC (default: 2)
- `--smoothing`: Iteraciones de suavizado (default: 0)

---

### 2ï¸âƒ£ Clustering (Opcional)

Separa nanoporos individuales:

```bash
# HDBSCAN (automÃ¡tico)
python main.py cluster surface.dump clusters_dir/ --method hdbscan

# KMeans (manual)
python main.py cluster surface.dump clusters_dir/ --method kmeans --n-clusters 5

# MeanShift (automÃ¡tico)
python main.py cluster surface.dump clusters_dir/ --method meanshift
```

**Salida:** Directorio con `cluster_0.dump`, `cluster_1.dump`, etc.

---

### 3ï¸âƒ£ Preprocesamiento (ExtracciÃ³n de Features)

Extrae 37 features geomÃ©tricas para Machine Learning:

```bash
python main.py preprocess surface_dumps_dir/ --output features.csv

# Con vacancias conocidas (para training)
python main.py preprocess dumps/ --output features.csv --vacancies-file vacancies.txt
```

**Features extraÃ­das (37 total):**
- 26 del grid 3D (ocupaciÃ³n, gradientes, fragmentaciÃ³n, etc.)
- 2 del Convex Hull (volumen, Ã¡rea)
- 3 momentos de inercia principales
- 2 radiales (RDF mean, kurtosis)
- 1 entropÃ­a espacial
- 1 bandwidth de clustering

---

### 4ï¸âƒ£ Training

Entrena modelo Random Forest:

```bash
python main.py train features.csv --output models/

# Con parÃ¡metros personalizados
python main.py train features.csv --output models/ \
    --n-estimators 200 \
    --test-size 0.3
```

**Salida:**
- `modelo_rf.joblib`: Modelo entrenado
- `feature_names.txt`: Nombres de features
- `feature_importance.csv`: Importancias

---

### 5ï¸âƒ£ PredicciÃ³n

Predice vacancias en nuevos dumps:

```bash
# Un archivo
python main.py predict models/modelo_rf.joblib new_dump.dump

# MÃºltiples archivos
python main.py predict models/modelo_rf.joblib dumps_dir/ --output predictions.csv
```

---

## ğŸ”§ Pipeline Completo (Ejemplo)

```bash
# 1. Detectar superficie (Alpha Shape)
for dump in raw_dumps/*.dump; do
    python main.py alpha_shape "$dump" "surface_dumps/$(basename $dump)"
done

# 2. Preprocesar: Extraer features (con vacancias conocidas)
python main.py preprocess surface_dumps/ --output features.csv --vacancies-file vacancies.txt

# 3. Entrenar modelo
python main.py train features.csv --output models/

# 4. Predecir en nuevos dumps
python main.py predict models/modelo_rf.joblib new_dumps/ --output predictions.csv
```

---

## ğŸ“Š Constantes Clave

Definidas en `utils/constants.py`:

- **A0**: 3.532 Ã… (parÃ¡metro de red FCC Cu)
- **ATM_TOTAL**: 16384 (Ã¡tomos totales esperados)
- **GRID_SIZE**: 10Ã—10Ã—10 (grid de ocupaciÃ³n)
- **DEFAULT_PROBE_RADIUS**: 2.0 Ã…

---

## ğŸ§© Algoritmos de Clustering

| Algoritmo | DescripciÃ³n | CuÃ¡ndo usar |
|-----------|-------------|-------------|
| **HDBSCAN** | JerÃ¡rquico basado en densidad | AutomÃ¡tico, detecta ruido |
| **KMeans** | Particionamiento en K clusters | NÃºmero conocido de clusters |
| **MeanShift** | Basado en densidad | EstimaciÃ³n automÃ¡tica |
| **Agglomerative** | JerÃ¡rquico aglomerativo | Dendrogramas, linkage |

---

## ğŸ“¦ Dependencias

**Core:**
- numpy
- pandas
- scipy
- scikit-learn
- joblib

**Opcional:**
- hdbscan (clustering avanzado)
- ovito (extracciÃ³n de superficie con OVITO)

---

## ğŸ”¬ CÃ³digo Recomendado por Etapa

Basado en el anÃ¡lisis del repositorio original:

| Etapa | CÃ³digo Base | RazÃ³n |
|-------|-------------|-------|
| **Alpha Shape** | `alpha_shape_ghost_particles.py` | Clase modular, sin Streamlit, auto-detecta lattice |
| **Clustering** | `cluster_app_spirit.py` | 4 algoritmos, mÃ©tricas completas |
| **Preprocesamiento** | `simplified_extractor_enhanced.py` | 37 features, PCA optimizado |
| **Training** | `train_simplified.py` | CÃ³digo limpio, 330 lÃ­neas |
| **PredicciÃ³n** | `vacancy_batch_predict.py` | Batch optimizado, consistente |

---

## ğŸ“ Ventajas del Software Unificado

âœ… **Sin Streamlit**: CLI puro, sin dependencias de UI
âœ… **Modular**: Cada etapa es independiente y reutilizable
âœ… **Consistente**: Parser LAMMPS y constantes unificadas
âœ… **Documentado**: Docstrings completas en cada mÃ³dulo
âœ… **Extensible**: FÃ¡cil agregar nuevos algoritmos

---

## ğŸ¯ Nomenclatura Correcta

- **Alpha Shape** = DetecciÃ³n de superficie (NO es preprocesamiento)
- **Preprocesamiento** = ExtracciÃ³n de features (preparaciÃ³n para ML)
- **Training** = Entrenamiento del modelo
- **PredicciÃ³n** = Inferencia de vacancias

---

## ğŸ¤ Contribuciones

Para agregar nuevos algoritmos o features:

1. Edita los mÃ³dulos en `core/`
2. Actualiza `FEATURE_ORDER` en `utils/constants.py` si cambias features
3. Crea tests para validar consistencia

---

## ğŸ“„ Licencia

[Especificar licencia del proyecto]

---

## ğŸ“§ Contacto

[InformaciÃ³n de contacto]
